"""
ä½¿ç”¨Rerunè¿›è¡ŒHDF5æœºå™¨äººæ•°æ®å¯è§†åŒ–ï¼ˆé€šç”¨ç‰ˆæœ¬ï¼‰

å®‰è£…ä¾èµ–:
    pip install rerun-sdk h5py numpy tqdm
    pip install opencv-python  # å¯é€‰ï¼Œç”¨äºæ›´å¥½çš„é¢œè‰²æ˜ å°„

ä½¿ç”¨ç¤ºä¾‹:
    # å¯è§†åŒ–å•ä¸ªæ–‡ä»¶
    python visual_hdf5_rerun.py /path/to/file.hdf5
    
    # å¯è§†åŒ–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    python visual_hdf5_rerun.py /path/to/folder/
    
    # ä¿å­˜ä¸º.rrdæ–‡ä»¶ä¾›åç»­æŸ¥çœ‹
    python visual_hdf5_rerun.py /path/to/file.hdf5 --save output.rrd
    
    # è¿æ¥åˆ°è¿œç¨‹æŸ¥çœ‹å™¨
    python visual_hdf5_rerun.py /path/to/file.hdf5 --connect
"""

import h5py
import numpy as np
import os
import json
import sys
from tqdm import tqdm
import argparse
from pathlib import Path
import base64
from io import BytesIO

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

from robot.utils.base.data_handler import debug_print

try:
    import rerun as rr
except ImportError:
    debug_print("RERUN", "æœªå®‰è£…rerun-sdkï¼Œè¯·è¿è¡Œ: pip install rerun-sdk", "ERROR")
    sys.exit(1)

try:
    from PIL import Image
    HAS_PIL = True
except ImportError:
    HAS_PIL = False

try:
    import cv2
    HAS_CV2 = True
except ImportError:
    HAS_CV2 = False


def detect_hdf5_format(f):
    """
    è‡ªåŠ¨æ£€æµ‹HDF5æ–‡ä»¶çš„æ ¼å¼ç±»å‹
    
    Returns:
        str: æ ¼å¼ç±»å‹ ('act', 'openpi', 'rdt', 'custom')
    """
    keys = list(f.keys())
    
    # æ£€æµ‹ACTæ ¼å¼ï¼ˆæœ‰left_arm, right_arm, cam_*ç­‰ï¼‰
    has_left_arm = any(k in keys for k in ['left_arm', 'slave_left_arm', 'master_left_arm'])
    has_right_arm = any(k in keys for k in ['right_arm', 'slave_right_arm', 'master_right_arm'])
    has_cam = any(k.startswith(('cam_', 'slave_cam_', 'master_cam_')) for k in keys)
    
    if has_left_arm or has_right_arm or has_cam:
        return 'act'
    
    # æ£€æµ‹OpenPIæ ¼å¼ï¼ˆæœ‰observations, actionç­‰ï¼‰
    if 'observations' in keys or 'action' in keys:
        return 'openpi'
    
    # æ£€æµ‹RDTæ ¼å¼
    if 'data' in keys and isinstance(f['data'], h5py.Group):
        return 'rdt'
    
    return 'custom'


def decode_image_from_bytes(img_bytes):
    """
    ä»å­—èŠ‚æ•°æ®è§£ç å›¾åƒ
    æ”¯æŒå¤šç§ç¼–ç æ ¼å¼ï¼šjpgã€pngã€base64ç­‰
    """
    if not HAS_PIL:
        return None
    
    try:
        # å°è¯•ç›´æ¥è§£ç 
        img = Image.open(BytesIO(img_bytes))
        return np.array(img)
    except:
        try:
            # å°è¯•base64è§£ç 
            img_data = base64.b64decode(img_bytes)
            img = Image.open(BytesIO(img_data))
            return np.array(img)
        except:
            return None


def extract_images_from_dataset(dataset, frame_idx):
    """
    ä»æ•°æ®é›†ä¸­æå–å›¾åƒ
    å¤„ç†å„ç§å¯èƒ½çš„å›¾åƒå­˜å‚¨æ ¼å¼
    """
    if frame_idx >= len(dataset):
        return None
    
    data = dataset[frame_idx]
    
    # æƒ…å†µ1: ç›´æ¥æ˜¯numpyæ•°ç»„å›¾åƒ
    if isinstance(data, np.ndarray):
        if len(data.shape) >= 2:  # å·²ç»æ˜¯å›¾åƒ
            return data
    
    # æƒ…å†µ2: å­—èŠ‚ä¸²ï¼ˆå‹ç¼©çš„å›¾åƒï¼‰
    if isinstance(data, (bytes, np.bytes_)):
        img = decode_image_from_bytes(data)
        if img is not None:
            return img
    
    # æƒ…å†µ3: å­—ç¬¦ä¸²ç±»å‹çš„numpyæ ‡é‡
    if hasattr(data, 'tobytes'):
        img = decode_image_from_bytes(data.tobytes())
        if img is not None:
            return img
    
    return None


def is_tactile_image_data(data, frame_idx=0):
    """
    æ£€æµ‹è§¦è§‰æ•°æ®æ˜¯å¦ä¸ºå›¾åƒæ ¼å¼
    è§¦è§‰å›¾åƒé€šå¸¸æ˜¯2Dçš„å‹åŠ›/æ¥è§¦å›¾
    
    æ”¯æŒä¸¤ç§æ ¼å¼:
    1. (n_frames, height, width) - æœ€å¸¸è§
    2. (height, width) - å•å¸§
    """
    if data is None:
        return False
    
    # æ£€æŸ¥æ•°æ®é›†çš„å½¢çŠ¶
    if hasattr(data, 'shape'):
        shape = data.shape
        # æ ¼å¼1: (n_frames, h, w) - å¤šå¸§è§¦è§‰å›¾åƒ
        if len(shape) == 3:
            n_frames, h, w = shape
            if 4 <= h <= 256 and 4 <= w <= 256:
                return True
        # æ ¼å¼2: (h, w) - å•å¸§è§¦è§‰å›¾åƒ
        elif len(shape) == 2:
            h, w = shape
            if 4 <= h <= 256 and 4 <= w <= 256:
                return True
    
    # å¦‚æœæœ‰frame_idxï¼Œæ£€æŸ¥å•å¸§æ•°æ®
    if frame_idx < len(data):
        try:
            frame_data = data[frame_idx]
            if isinstance(frame_data, np.ndarray) and len(frame_data.shape) == 2:
                h, w = frame_data.shape
                if 4 <= h <= 256 and 4 <= w <= 256:
                    return True
        except:
            pass
    
    return False


def apply_tactile_colormap(tactile_data):
    """
    ä¸ºè§¦è§‰æ•°æ®åº”ç”¨é¢œè‰²æ˜ å°„
    å°†è§¦è§‰å‹åŠ›æ•°æ®è½¬æ¢ä¸ºå½©è‰²çƒ­åŠ›å›¾
    """
    # å½’ä¸€åŒ–åˆ°0-255
    if tactile_data.dtype != np.uint8:
        if tactile_data.max() > tactile_data.min():
            normalized = (tactile_data - tactile_data.min()) / (tactile_data.max() - tactile_data.min())
            normalized = (normalized * 255).astype(np.uint8)
        else:
            normalized = np.zeros_like(tactile_data, dtype=np.uint8)
    else:
        normalized = tactile_data
    
    # ä½¿ç”¨VIRIDISé¢œè‰²æ˜ å°„ï¼ˆç±»ä¼¼OpenCVçš„COLORMAP_VIRIDISï¼‰
    # Rerunéœ€è¦RGBæ ¼å¼ï¼Œæˆ‘ä»¬æ‰‹åŠ¨åˆ›å»ºä¸€ä¸ªç±»ä¼¼viridisçš„æ˜ å°„
    # ä¸ºäº†æ›´å¥½çš„æ˜¾ç¤ºæ•ˆæœï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªRGBç‰ˆæœ¬
    if HAS_CV2:
        # å¦‚æœæœ‰OpenCVï¼Œä½¿ç”¨VIRIDIS colormap
        colored = cv2.applyColorMap(normalized, cv2.COLORMAP_VIRIDIS)
        # OpenCVè¿”å›BGRï¼Œè½¬æ¢ä¸ºRGB
        colored = cv2.cvtColor(colored, cv2.COLOR_BGR2RGB)
        return colored
    
    # å¦‚æœæ²¡æœ‰OpenCVï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„è“-ç»¿-é»„-çº¢æ˜ å°„
    h, w = normalized.shape
    colored = np.zeros((h, w, 3), dtype=np.uint8)
    
    # ç®€å•çš„hot colormap: è“->ç»¿->é»„->çº¢
    for i in range(h):
        for j in range(w):
            val = normalized[i, j] / 255.0
            if val < 0.25:
                # è“åˆ°é’
                colored[i, j] = [0, int(val * 4 * 255), 255]
            elif val < 0.5:
                # é’åˆ°ç»¿
                t = (val - 0.25) * 4
                colored[i, j] = [0, 255, int((1-t) * 255)]
            elif val < 0.75:
                # ç»¿åˆ°é»„
                t = (val - 0.5) * 4
                colored[i, j] = [int(t * 255), 255, 0]
            else:
                # é»„åˆ°çº¢
                t = (val - 0.75) * 4
                colored[i, j] = [255, int((1-t) * 255), 0]
    
    return colored


def log_timeseries_data(entity_path, data, frame_idx, name_prefix="value"):
    """
    è®°å½•æ—¶é—´åºåˆ—æ•°æ®åˆ°Rerun
    è‡ªåŠ¨å¤„ç†æ ‡é‡ã€å‘é‡å’Œå¤šç»´æ•°æ®
    """
    # å¦‚æœæ•°æ®ä¸ºNoneæˆ–ç©ºï¼Œç›´æ¥è¿”å›ï¼Œä¸è®°å½•ä»»ä½•å†…å®¹
    if data is None or len(data) == 0 or frame_idx >= len(data):
        return
    
    frame_data = data[frame_idx]
    
    # æ ‡é‡
    if np.isscalar(frame_data) or (isinstance(frame_data, np.ndarray) and frame_data.size == 1):
        value = float(frame_data) if not isinstance(frame_data, np.ndarray) else float(frame_data.item())
        rr.log(entity_path, rr.Scalars([value]))
    
    # å‘é‡
    elif isinstance(frame_data, np.ndarray):
        if len(frame_data.shape) == 1:
            # 1Då‘é‡ - è®°å½•æ¯ä¸ªå…ƒç´ 
            for i, val in enumerate(frame_data):
                rr.log(f"{entity_path}/{name_prefix}_{i+1}", rr.Scalars([float(val)]))
            # ä¹Ÿè®°å½•æ•´ä¸ªå‘é‡
            rr.log(f"{entity_path}_vector", rr.Tensor(frame_data, dim_names=["dim"]))
        else:
            # å¤šç»´æ•°æ® - ä½œä¸ºå¼ é‡
            rr.log(entity_path, rr.Tensor(frame_data))


def visualize_act_format(f, verbose=False):
    """å¤„ç†ACTæ ¼å¼çš„HDF5æ–‡ä»¶"""
    if verbose:
        debug_print("ACT_FORMAT", "æ£€æµ‹åˆ°ACTæ ¼å¼æ•°æ®", "DEBUG")
    
    # è¯»å–å·¦è‡‚æ•°æ®
    left_arm_data = {'joints': None, 'gripper': None, 'eefort': None}
    left_arm_keys = ['left_arm', 'slave_left_arm', 'master_left_arm']
    for key in left_arm_keys:
        if key in f:
            left_arm_group = f[key]
            if 'joint' in left_arm_group and len(left_arm_group['joint']) > 0:
                left_arm_data['joints'] = left_arm_group['joint'][:]
            if 'gripper' in left_arm_group and len(left_arm_group['gripper']) > 0:
                left_arm_data['gripper'] = left_arm_group['gripper'][:]
            if 'eefort' in left_arm_group and len(left_arm_group['eefort']) > 0:
                left_arm_data['eefort'] = left_arm_group['eefort'][:]
            break
    
    # è¯»å–å³è‡‚æ•°æ®
    right_arm_data = {'joints': None, 'gripper': None, 'eefort': None}
    right_arm_keys = ['right_arm', 'slave_right_arm', 'master_right_arm']
    for key in right_arm_keys:
        if key in f:
            right_arm_group = f[key]
            if 'joint' in right_arm_group and len(right_arm_group['joint']) > 0:
                right_arm_data['joints'] = right_arm_group['joint'][:]
            if 'gripper' in right_arm_group and len(right_arm_group['gripper']) > 0:
                right_arm_data['gripper'] = right_arm_group['gripper'][:]
            if 'eefort' in right_arm_group and len(right_arm_group['eefort']) > 0:
                right_arm_data['eefort'] = right_arm_group['eefort'][:]
            break
    
    # è¯»å–ç›¸æœºæ•°æ®
    camera_data = {}
    for key in f.keys():
        if (key.startswith('cam_') or key.startswith('camera_') or 
            key.startswith('slave_cam_') or key.startswith('master_cam_')):
            if key in f:
                cam_dataset = None
                if 'color' in f[key]:
                    cam_dataset = f[key]['color']
                elif 'rgb' in f[key]:
                    cam_dataset = f[key]['rgb']
                elif 'image' in f[key]:
                    cam_dataset = f[key]['image']
                
                # åªæ·»åŠ éç©ºçš„ç›¸æœºæ•°æ®é›†
                if cam_dataset is not None and len(cam_dataset) > 0:
                    camera_data[key] = cam_dataset
    
    # è¯»å–è§¦è§‰æ•°æ®
    tactile_data = {}
    tactile_keywords = ['tactile', 'force', 'pressure', 'touch', 'tac', 'vitac', 'contact', 
                        'haptic', 'sensor_force', 'torque_sensor']
    
    def search_tactile_data(group, prefix=""):
        """é€’å½’æœç´¢è§¦è§‰æ•°æ®"""
        for key in group.keys():
            full_path = f"{prefix}/{key}" if prefix else key
            item = group[key]
            
            # æ£€æŸ¥æ˜¯å¦åŒ¹é…è§¦è§‰å…³é”®è¯
            if any(keyword in key.lower() for keyword in tactile_keywords):
                if isinstance(item, h5py.Dataset):
                    # ç›´æ¥æ˜¯Datasetï¼Œåªæ·»åŠ éç©ºæ•°æ®é›†
                    if len(item) > 0:
                        tactile_data[full_path] = item
                elif isinstance(item, h5py.Group):
                    # æ˜¯Groupï¼Œç»§ç»­é€’å½’æœç´¢å…¶å­é¡¹
                    search_tactile_data(item, full_path)
            elif isinstance(item, h5py.Group):
                # å³ä½¿åå­—ä¸åŒ¹é…ï¼Œä¹Ÿæœç´¢Groupå†…éƒ¨ï¼ˆå¯èƒ½åŒ…å«tactileå­é¡¹ï¼‰
                # ç‰¹åˆ«æ˜¯å¤„ç†åƒ slave_right_arm_tac/tactile è¿™æ ·çš„ç»“æ„
                search_tactile_data(item, full_path)
    
    search_tactile_data(f)
    
    # è°ƒè¯•ï¼šæ‰“å°æ‰¾åˆ°çš„è§¦è§‰æ•°æ®
    if verbose:
        if tactile_data:
            debug_print("ACT_FORMAT", f"æ‰¾åˆ° {len(tactile_data)} ä¸ªè§¦è§‰æ•°æ®é›†:", "DEBUG")
            for tac_name, tac_dataset in tactile_data.items():
                debug_print("ACT_FORMAT", f"  - {tac_name}: é•¿åº¦={len(tac_dataset)}", "DEBUG")
        else:
            debug_print("ACT_FORMAT", "æœªæ‰¾åˆ°è§¦è§‰æ•°æ®", "DEBUG")
    
    # ç¡®å®šæœ€å¤§å¸§æ•°
    max_frames = 0
    if camera_data:
        max_frames = max(len(cam) for cam in camera_data.values())
    if left_arm_data['joints'] is not None:
        max_frames = max(max_frames, len(left_arm_data['joints']))
    if right_arm_data['joints'] is not None:
        max_frames = max(max_frames, len(right_arm_data['joints']))
    
    return left_arm_data, right_arm_data, camera_data, tactile_data, max_frames


def visualize_openpi_format(f, verbose=False):
    """å¤„ç†OpenPIæ ¼å¼çš„HDF5æ–‡ä»¶"""
    if verbose:
        debug_print("OPENPI_FORMAT", "æ£€æµ‹åˆ°OpenPIæ ¼å¼æ•°æ®", "DEBUG")
    
    robot_data = {}
    camera_data = {}
    max_frames = 0
    
    # å¤„ç†observations
    if 'observations' in f:
        obs_group = f['observations']
        
        # å¤„ç†qposï¼ˆå…³èŠ‚ä½ç½®ï¼‰
        if 'qpos' in obs_group and len(obs_group['qpos']) > 0:
            robot_data['qpos'] = obs_group['qpos'][:]
            max_frames = max(max_frames, len(robot_data['qpos']))
        
        # å¤„ç†qvelï¼ˆå…³èŠ‚é€Ÿåº¦ï¼‰
        if 'qvel' in obs_group and len(obs_group['qvel']) > 0:
            robot_data['qvel'] = obs_group['qvel'][:]
            max_frames = max(max_frames, len(robot_data['qvel']))
        
        # å¤„ç†effortï¼ˆå…³èŠ‚åŠ›çŸ©ï¼‰
        if 'effort' in obs_group and len(obs_group['effort']) > 0:
            robot_data['effort'] = obs_group['effort'][:]
            max_frames = max(max_frames, len(robot_data['effort']))
        
        # å¤„ç†å›¾åƒæ•°æ®
        if 'images' in obs_group:
            img_group = obs_group['images']
            for img_key in img_group.keys():
                # åªæ·»åŠ éç©ºçš„å›¾åƒæ•°æ®é›†
                if len(img_group[img_key]) > 0:
                    camera_data[img_key] = img_group[img_key]
                    max_frames = max(max_frames, len(img_group[img_key]))
    
    # å¤„ç†action
    if 'action' in f and len(f['action']) > 0:
        robot_data['action'] = f['action'][:]
        max_frames = max(max_frames, len(robot_data['action']))
    
    return robot_data, camera_data, max_frames


def visualize_custom_format(f, verbose=False):
    """å¤„ç†è‡ªå®šä¹‰æ ¼å¼çš„HDF5æ–‡ä»¶ - è‡ªåŠ¨æ¢æµ‹æ‰€æœ‰æ•°æ®"""
    if verbose:
        debug_print("CUSTOM_FORMAT", "æ£€æµ‹åˆ°è‡ªå®šä¹‰æ ¼å¼æ•°æ®ï¼Œè‡ªåŠ¨æ¢æµ‹ç»“æ„...", "DEBUG")
    
    datasets = {}
    images = {}
    tactile_images = {}  # å•ç‹¬å­˜å‚¨è§¦è§‰å›¾åƒ
    max_frames = 0
    
    # è§¦è§‰æ•°æ®å…³é”®è¯
    tactile_keywords = ['tactile', 'force', 'pressure', 'touch', 'tac', 'vitac', 'contact', 
                        'haptic', 'sensor_force', 'torque_sensor']
    
    def explore_group(group, prefix=""):
        """é€’å½’æ¢ç´¢HDF5ç»„"""
        nonlocal max_frames
        
        for key in group.keys():
            full_path = f"{prefix}/{key}" if prefix else key
            item = group[key]
            
            if isinstance(item, h5py.Dataset):
                data = item
                
                # è·³è¿‡ç©ºæ•°æ®é›†
                if len(data) == 0:
                    continue
                
                max_frames = max(max_frames, len(data))
                
                # åˆ¤æ–­æ˜¯å¦æ˜¯å›¾åƒæ•°æ®
                # æ£€æŸ¥ç¬¬ä¸€ä¸ªå…ƒç´ 
                first_elem = data[0]
                is_image = False
                is_tactile = any(keyword in full_path.lower() for keyword in tactile_keywords)
                
                # å­—èŠ‚ä¸²å¯èƒ½æ˜¯å‹ç¼©çš„å›¾åƒ
                if isinstance(first_elem, (bytes, np.bytes_)) or (
                    isinstance(first_elem, np.ndarray) and first_elem.dtype.kind in ['S', 'O']
                ):
                    is_image = True
                    if is_tactile:
                        tactile_images[full_path] = data
                    else:
                        images[full_path] = data
                # numpyæ•°ç»„ä¸”å½¢çŠ¶åƒå›¾åƒ
                elif isinstance(first_elem, np.ndarray) and len(first_elem.shape) in [2, 3]:
                    if len(first_elem.shape) == 3 and first_elem.shape[2] in [1, 3, 4]:
                        is_image = True
                        if is_tactile:
                            tactile_images[full_path] = data
                        else:
                            images[full_path] = data
                    elif len(first_elem.shape) == 2:
                        # 2Dæ•°æ®å¯èƒ½æ˜¯è§¦è§‰å›¾åƒæˆ–æ™®é€šå›¾åƒ
                        h, w = first_elem.shape
                        # è§¦è§‰ä¼ æ„Ÿå™¨é€šå¸¸æ˜¯å°å°ºå¯¸çš„æ–¹é˜µ
                        if is_tactile or (4 <= h <= 256 and 4 <= w <= 256 and abs(h - w) <= max(h, w) * 0.5):
                            is_image = True
                            tactile_images[full_path] = data
                        elif min(first_elem.shape) > 10:
                            is_image = True
                            images[full_path] = data
                
                if not is_image:
                    # åªå­˜å‚¨éç©ºæ•°æ®
                    data_array = data[:]
                    if data_array is not None and len(data_array) > 0:
                        datasets[full_path] = data_array
                    
            elif isinstance(item, h5py.Group):
                explore_group(item, full_path)
    
    explore_group(f)
    
    # è°ƒè¯•ï¼šæ‰“å°æ‰¾åˆ°çš„æ•°æ®
    if verbose:
        if tactile_images:
            debug_print("CUSTOM_FORMAT", f"æ‰¾åˆ° {len(tactile_images)} ä¸ªè§¦è§‰å›¾åƒæ•°æ®é›†:", "DEBUG")
            for tac_name in tactile_images.keys():
                debug_print("CUSTOM_FORMAT", f"  - {tac_name}", "DEBUG")
        else:
            debug_print("CUSTOM_FORMAT", "æœªæ‰¾åˆ°è§¦è§‰å›¾åƒæ•°æ®", "DEBUG")
    
    return datasets, images, tactile_images, max_frames


def visualize_hdf5_with_rerun(hdf5_path, verbose=False):
    """
    ä½¿ç”¨Rerunå¯è§†åŒ–HDF5æ–‡ä»¶å†…å®¹ï¼ˆé€šç”¨ç‰ˆæœ¬ï¼‰
    è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶æ ¼å¼å¹¶é€‚é…
    
    Parameters:
        hdf5_path: HDF5æ–‡ä»¶è·¯å¾„
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    """
    # æ‰“å¼€HDF5æ–‡ä»¶
    with h5py.File(hdf5_path, 'r') as f:
        if verbose:
            debug_print("VISUALIZE", f"å¤„ç†æ–‡ä»¶: {os.path.basename(hdf5_path)}", "INFO")
        
        # è‡ªåŠ¨æ£€æµ‹æ ¼å¼
        data_format = detect_hdf5_format(f)
        if verbose:
            debug_print("VISUALIZE", f"æ•°æ®æ ¼å¼: {data_format.upper()}", "DEBUG")
        
        # æ ¹æ®æ ¼å¼å¤„ç†æ•°æ®
        max_frames = 0
        
        if data_format == 'act':
            left_arm_data, right_arm_data, camera_data, tactile_data, max_frames = visualize_act_format(f, verbose)
            
            if max_frames == 0:
                debug_print("VISUALIZE", f"æ–‡ä»¶ {hdf5_path} ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ•°æ®", "WARNING")
                return
            
            if verbose:
                debug_print("DATA_STATS", f"æ€»å¸§æ•°: {max_frames}", "DEBUG")
                if camera_data:
                    debug_print("DATA_STATS", f"ç›¸æœºæ•°é‡: {len(camera_data)}", "DEBUG")
                    for cam_name in camera_data.keys():
                        debug_print("DATA_STATS", f"  - {cam_name}", "DEBUG")
                if tactile_data:
                    debug_print("DATA_STATS", f"è§¦è§‰ä¼ æ„Ÿå™¨: {len(tactile_data)}", "DEBUG")
                    for tac_name, tac_dataset in tactile_data.items():
                        debug_print("DATA_STATS", f"  - {tac_name}: é•¿åº¦={len(tac_dataset)}", "DEBUG")
                else:
                    debug_print("DATA_STATS", "è§¦è§‰ä¼ æ„Ÿå™¨: 0 (æ— è§¦è§‰æ•°æ®)", "DEBUG")
                if left_arm_data['joints'] is not None:
                    debug_print("DATA_STATS", f"å·¦è‡‚å…³èŠ‚: {left_arm_data['joints'].shape}", "DEBUG")
                if right_arm_data['joints'] is not None:
                    debug_print("DATA_STATS", f"å³è‡‚å…³èŠ‚: {right_arm_data['joints'].shape}", "DEBUG")
            
            # è®°å½•ACTæ ¼å¼æ•°æ®
            debug_print("VISUALIZE", "æ­£åœ¨è®°å½•æ•°æ®åˆ°Rerun...", "INFO")
            if verbose:
                debug_print("VISUALIZE", f"å°†è¦è®°å½•çš„æ•°æ®ç±»å‹:", "DEBUG")
                debug_print("VISUALIZE", f"  - å·¦è‡‚: {left_arm_data['joints'] is not None}", "DEBUG")
                debug_print("VISUALIZE", f"  - å³è‡‚: {right_arm_data['joints'] is not None}", "DEBUG")
                debug_print("VISUALIZE", f"  - ç›¸æœº: {len(camera_data) if camera_data else 0}", "DEBUG")
                debug_print("VISUALIZE", f"  - è§¦è§‰: {len(tactile_data) if tactile_data else 0}", "DEBUG")
            
            for frame_idx in tqdm(range(max_frames), desc="è®°å½•å¸§æ•°æ®", disable=not verbose):
                rr.set_time("frame", sequence=frame_idx)
                
                # å·¦è‡‚æ•°æ® - åªåœ¨æ•°æ®å­˜åœ¨æ—¶è®°å½•
                if left_arm_data['joints'] is not None and len(left_arm_data['joints']) > 0:
                    log_timeseries_data("robot/left_arm/joints", left_arm_data['joints'], frame_idx, "joint")
                if left_arm_data['gripper'] is not None and len(left_arm_data['gripper']) > 0:
                    log_timeseries_data("robot/left_arm/gripper", left_arm_data['gripper'], frame_idx, "gripper")
                if left_arm_data['eefort'] is not None and len(left_arm_data['eefort']) > 0:
                    log_timeseries_data("robot/left_arm/eefort", left_arm_data['eefort'], frame_idx, "force")
                
                # å³è‡‚æ•°æ® - åªåœ¨æ•°æ®å­˜åœ¨æ—¶è®°å½•
                if right_arm_data['joints'] is not None and len(right_arm_data['joints']) > 0:
                    log_timeseries_data("robot/right_arm/joints", right_arm_data['joints'], frame_idx, "joint")
                if right_arm_data['gripper'] is not None and len(right_arm_data['gripper']) > 0:
                    log_timeseries_data("robot/right_arm/gripper", right_arm_data['gripper'], frame_idx, "gripper")
                if right_arm_data['eefort'] is not None and len(right_arm_data['eefort']) > 0:
                    log_timeseries_data("robot/right_arm/eefort", right_arm_data['eefort'], frame_idx, "force")
                
                # ç›¸æœºå›¾åƒ - åªåœ¨æœ‰ç›¸æœºæ•°æ®æ—¶è®°å½•
                if camera_data:
                    for camera_name, cam_dataset in camera_data.items():
                        if frame_idx < len(cam_dataset):
                            image = extract_images_from_dataset(cam_dataset, frame_idx)
                            if image is not None:
                                # ç¡®ä¿å›¾åƒæ ¼å¼æ­£ç¡®
                                if image.dtype != np.uint8:
                                    if image.max() > 0:
                                        image = (image - image.min()) / (image.max() - image.min()) * 255
                                    image = image.astype(np.uint8)
                                
                                # RerunæœŸæœ›RGBæ ¼å¼
                                if len(image.shape) == 2:
                                    image = np.stack([image, image, image], axis=-1)
                                elif len(image.shape) == 3 and image.shape[2] == 4:
                                    image = image[:, :, :3]
                                
                                rr.log(f"cameras/{camera_name}", rr.Image(image))
                
                # è§¦è§‰æ•°æ® - åªåœ¨æœ‰è§¦è§‰æ•°æ®æ—¶è®°å½•
                if tactile_data:
                    # åœ¨ç¬¬ä¸€å¸§æ—¶è®°å½•è°ƒè¯•ä¿¡æ¯
                    if frame_idx == 0 and verbose:
                        debug_print("VISUALIZE", f"å¼€å§‹è®°å½• {len(tactile_data)} ä¸ªè§¦è§‰æ•°æ®é›†", "DEBUG")
                    
                    for tactile_name, tactile_dataset in tactile_data.items():
                        if frame_idx < len(tactile_dataset):
                            # æ£€æµ‹æ˜¯å¦ä¸ºè§¦è§‰å›¾åƒæ•°æ®
                            if is_tactile_image_data(tactile_dataset, frame_idx):
                                tactile_frame = tactile_dataset[frame_idx]
                                # åº”ç”¨çƒ­åŠ›å›¾é¢œè‰²æ˜ å°„
                                tactile_colored = apply_tactile_colormap(tactile_frame)
                                rr.log(f"tactile/{tactile_name}_heatmap", rr.Image(tactile_colored))
                                # åŒæ—¶è®°å½•åŸå§‹æ•°æ®çš„å¼ é‡è¡¨ç¤º
                                rr.log(f"tactile/{tactile_name}_raw", rr.Tensor(tactile_frame))
                            else:
                                # éå›¾åƒæ ¼å¼çš„è§¦è§‰æ•°æ®ï¼Œä½¿ç”¨æ—¶é—´åºåˆ—æ˜¾ç¤º
                                log_timeseries_data(f"tactile/{tactile_name}", tactile_dataset, frame_idx)
        
        elif data_format == 'openpi':
            robot_data, camera_data, max_frames = visualize_openpi_format(f, verbose)
            
            if max_frames == 0:
                debug_print("VISUALIZE", f"æ–‡ä»¶ {hdf5_path} ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ•°æ®", "WARNING")
                return
            
            if verbose:
                debug_print("DATA_STATS", f"æ€»å¸§æ•°: {max_frames}", "DEBUG")
                if robot_data:
                    debug_print("DATA_STATS", f"æœºå™¨äººæ•°æ®: {list(robot_data.keys())}", "DEBUG")
                if camera_data:
                    debug_print("DATA_STATS", f"ç›¸æœºæ•°é‡: {len(camera_data)}", "DEBUG")
            
            # è®°å½•OpenPIæ ¼å¼æ•°æ®
            debug_print("VISUALIZE", "æ­£åœ¨è®°å½•æ•°æ®åˆ°Rerun...", "INFO")
            for frame_idx in tqdm(range(max_frames), desc="è®°å½•å¸§æ•°æ®", disable=not verbose):
                rr.set_time("frame", sequence=frame_idx)
                
                # æœºå™¨äººæ•°æ® - åªåœ¨æœ‰æ•°æ®æ—¶è®°å½•
                if robot_data:
                    for data_name, data_array in robot_data.items():
                        if data_array is not None and len(data_array) > 0:
                            log_timeseries_data(f"robot/{data_name}", data_array, frame_idx, "dim")
                
                # ç›¸æœºå›¾åƒ - åªåœ¨æœ‰ç›¸æœºæ•°æ®æ—¶è®°å½•
                if camera_data:
                    for camera_name, cam_dataset in camera_data.items():
                        if frame_idx < len(cam_dataset):
                            image = extract_images_from_dataset(cam_dataset, frame_idx)
                            if image is not None:
                                # ç¡®ä¿å›¾åƒæ ¼å¼æ­£ç¡®
                                if image.dtype != np.uint8:
                                    if image.max() > 0:
                                        image = (image - image.min()) / (image.max() - image.min()) * 255
                                    image = image.astype(np.uint8)
                                
                                if len(image.shape) == 2:
                                    image = np.stack([image, image, image], axis=-1)
                                elif len(image.shape) == 3 and image.shape[2] == 4:
                                    image = image[:, :, :3]
                                
                                rr.log(f"cameras/{camera_name}", rr.Image(image))
        
        else:  # custom format
            datasets, images, tactile_images, max_frames = visualize_custom_format(f, verbose)
            
            if max_frames == 0:
                debug_print("VISUALIZE", f"æ–‡ä»¶ {hdf5_path} ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ•°æ®", "WARNING")
                return
            
            if verbose:
                debug_print("DATA_STATS", f"æ€»å¸§æ•°: {max_frames}", "DEBUG")
                if datasets:
                    debug_print("DATA_STATS", f"æ•°æ®é›†æ•°é‡: {len(datasets)}", "DEBUG")
                    debug_print("DATA_STATS", "æ•°æ®é›†:", "DEBUG")
                    for name, data in list(datasets.items())[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                        debug_print("DATA_STATS", f"  - {name}: {data.shape}", "DEBUG")
                if images:
                    debug_print("DATA_STATS", f"å›¾åƒæ•°é‡: {len(images)}", "DEBUG")
                    debug_print("DATA_STATS", "å›¾åƒ:", "DEBUG")
                    for name in list(images.keys())[:10]:
                        debug_print("DATA_STATS", f"  - {name}", "DEBUG")
                if tactile_images:
                    debug_print("DATA_STATS", f"è§¦è§‰å›¾åƒæ•°é‡: {len(tactile_images)}", "DEBUG")
                    debug_print("DATA_STATS", "è§¦è§‰å›¾åƒ:", "DEBUG")
                    for name in list(tactile_images.keys())[:10]:
                        debug_print("DATA_STATS", f"  - {name}", "DEBUG")
            
            # è®°å½•è‡ªå®šä¹‰æ ¼å¼æ•°æ®
            debug_print("VISUALIZE", "æ­£åœ¨è®°å½•æ•°æ®åˆ°Rerun...", "INFO")
            if verbose:
                debug_print("VISUALIZE", f"å°†è¦è®°å½•çš„æ•°æ®ç±»å‹:", "DEBUG")
                debug_print("VISUALIZE", f"  - æ•°å€¼æ•°æ®: {len(datasets) if datasets else 0}", "DEBUG")
                debug_print("VISUALIZE", f"  - æ™®é€šå›¾åƒ: {len(images) if images else 0}", "DEBUG")
                debug_print("VISUALIZE", f"  - è§¦è§‰å›¾åƒ: {len(tactile_images) if tactile_images else 0}", "DEBUG")
            
            for frame_idx in tqdm(range(max_frames), desc="è®°å½•å¸§æ•°æ®", disable=not verbose):
                rr.set_time("frame", sequence=frame_idx)
                
                # æ•°å€¼æ•°æ® - åªåœ¨æœ‰æ•°æ®æ—¶è®°å½•
                if datasets:
                    for data_name, data_array in datasets.items():
                        if data_array is not None and len(data_array) > 0:
                            log_timeseries_data(f"data/{data_name}", data_array, frame_idx, "value")
                
                # æ™®é€šå›¾åƒæ•°æ® - åªåœ¨æœ‰å›¾åƒæ•°æ®æ—¶è®°å½•
                if images:
                    for img_name, img_dataset in images.items():
                        if frame_idx < len(img_dataset):
                            image = extract_images_from_dataset(img_dataset, frame_idx)
                            if image is not None:
                                # ç¡®ä¿å›¾åƒæ ¼å¼æ­£ç¡®
                                if image.dtype != np.uint8:
                                    if image.max() > 0:
                                        image = (image - image.min()) / (image.max() - image.min()) * 255
                                    image = image.astype(np.uint8)
                                
                                if len(image.shape) == 2:
                                    image = np.stack([image, image, image], axis=-1)
                                elif len(image.shape) == 3 and image.shape[2] == 4:
                                    image = image[:, :, :3]
                                
                                rr.log(f"images/{img_name}", rr.Image(image))
                
                # è§¦è§‰å›¾åƒæ•°æ®ï¼ˆç”¨çƒ­åŠ›å›¾æ˜¾ç¤ºï¼‰ - åªåœ¨æœ‰è§¦è§‰æ•°æ®æ—¶è®°å½•
                if tactile_images:
                    # åœ¨ç¬¬ä¸€å¸§æ—¶è®°å½•è°ƒè¯•ä¿¡æ¯
                    if frame_idx == 0 and verbose:
                        debug_print("VISUALIZE", f"å¼€å§‹è®°å½• {len(tactile_images)} ä¸ªè§¦è§‰å›¾åƒæ•°æ®é›†", "DEBUG")
                    
                    for tactile_name, tactile_dataset in tactile_images.items():
                        if frame_idx < len(tactile_dataset):
                            tactile_frame = extract_images_from_dataset(tactile_dataset, frame_idx)
                            if tactile_frame is not None:
                                # å¦‚æœæ˜¯2Dæ•°æ®ï¼Œåº”ç”¨çƒ­åŠ›å›¾
                                if len(tactile_frame.shape) == 2:
                                    tactile_colored = apply_tactile_colormap(tactile_frame)
                                    rr.log(f"tactile/{tactile_name}_heatmap", rr.Image(tactile_colored))
                                    # åŒæ—¶è®°å½•åŸå§‹æ•°æ®
                                    rr.log(f"tactile/{tactile_name}_raw", rr.Tensor(tactile_frame))
                                else:
                                    # å¦‚æœå·²ç»æ˜¯å½©è‰²å›¾åƒï¼Œç›´æ¥æ˜¾ç¤º
                                    if tactile_frame.dtype != np.uint8:
                                        if tactile_frame.max() > 0:
                                            tactile_frame = (tactile_frame - tactile_frame.min()) / (tactile_frame.max() - tactile_frame.min()) * 255
                                        tactile_frame = tactile_frame.astype(np.uint8)
                                    rr.log(f"tactile/{tactile_name}", rr.Image(tactile_frame))
        
        if verbose:
            debug_print("VISUALIZE", f"å®Œæˆè®°å½• {max_frames} å¸§æ•°æ®", "INFO")


def visualize_folder_with_rerun(folder_path, verbose=False):
    """
    ä½¿ç”¨Rerunå¯è§†åŒ–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰HDF5æ–‡ä»¶ï¼ˆé€’å½’æœç´¢ï¼‰
    
    Parameters:
        folder_path: æ–‡ä»¶å¤¹è·¯å¾„
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    """
    if not os.path.exists(folder_path):
        debug_print("FOLDER", f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}", "ERROR")
        return
    
    # é€’å½’æŸ¥æ‰¾æ‰€æœ‰HDF5æ–‡ä»¶
    hdf5_files = []
    for root, dirs, files in os.walk(folder_path):
        for file in files:
            if file.endswith('.hdf5') or file.endswith('.h5'):
                hdf5_files.append(os.path.join(root, file))
    
    if not hdf5_files:
        debug_print("FOLDER", f"åœ¨æ–‡ä»¶å¤¹ {folder_path} ä¸­æœªæ‰¾åˆ°HDF5æ–‡ä»¶", "ERROR")
        return
    
    debug_print("FOLDER", f"æ‰¾åˆ° {len(hdf5_files)} ä¸ªHDF5æ–‡ä»¶", "INFO")
    
    # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„recording
    for i, hdf5_file in enumerate(hdf5_files):
        file_name = os.path.basename(hdf5_file)
        rel_path = os.path.relpath(hdf5_file, folder_path)
        
        # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºç‹¬ç«‹çš„åº”ç”¨ID
        rr.init(f"hdf5_visualization/{rel_path}", spawn=False)
        
        if verbose:
            debug_print("FOLDER", f"[{i+1}/{len(hdf5_files)}] å¤„ç†æ–‡ä»¶: {rel_path}", "INFO")
        
        try:
            visualize_hdf5_with_rerun(hdf5_file, verbose=verbose)
        except Exception as e:
            debug_print("FOLDER", f"å¤„ç†æ–‡ä»¶ {file_name} æ—¶å‡ºé”™: {e}", "ERROR")
            if verbose:
                import traceback
                traceback.print_exc()


def explore_hdf5_structure(hdf5_path):
    """
    æ¢ç´¢å¹¶æ‰“å°HDF5æ–‡ä»¶ç»“æ„
    
    Parameters:
        hdf5_path: HDF5æ–‡ä»¶è·¯å¾„
    """
    debug_print("EXPLORE", f"HDF5æ–‡ä»¶ç»“æ„: {os.path.basename(hdf5_path)}", "INFO")
    with h5py.File(hdf5_path, 'r') as f:
        def print_structure(name, obj, indent=0):
            prefix = "  " * indent
            if isinstance(obj, h5py.Dataset):
                debug_print("EXPLORE", f"{prefix}ğŸ“Š æ•°æ®é›†: {name}", "DEBUG")
                debug_print("EXPLORE", f"{prefix}   å½¢çŠ¶: {obj.shape}, ç±»å‹: {obj.dtype}", "DEBUG")
            elif isinstance(obj, h5py.Group):
                debug_print("EXPLORE", f"{prefix}ğŸ“ ç»„: {name}", "DEBUG")
                for key in obj.keys():
                    print_structure(f"{name}/{key}", obj[key], indent + 1)
        
        for key in f.keys():
            print_structure(key, f[key])


def main():
    os.environ["INFO_LEVEL"] = "INFO"
    parser = argparse.ArgumentParser(
        description='ä½¿ç”¨Rerunè¿›è¡ŒHDF5æœºå™¨äººæ•°æ®å¯è§†åŒ–',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å¯è§†åŒ–å•ä¸ªæ–‡ä»¶ï¼ˆåœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ï¼‰
  python visual_hdf5_rerun.py data.hdf5
  
  # å¯è§†åŒ–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
  python visual_hdf5_rerun.py /path/to/folder/
  
  # ä¿å­˜ä¸º.rrdæ–‡ä»¶ä¾›åç»­æŸ¥çœ‹
  python visual_hdf5_rerun.py data.hdf5 --save output.rrd
  
  # è¿æ¥åˆ°è¿œç¨‹RerunæŸ¥çœ‹å™¨
  python visual_hdf5_rerun.py data.hdf5 --connect
  
  # æŸ¥çœ‹æ–‡ä»¶ç»“æ„
  python visual_hdf5_rerun.py data.hdf5 --explore
        """
    )
    
    parser.add_argument('input_path', help='è¾“å…¥HDF5æ–‡ä»¶æˆ–åŒ…å«HDF5æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('-v', '--verbose', action='store_true', help='å¯ç”¨è¯¦ç»†è¾“å‡º')
    parser.add_argument('-s', '--save', type=str, help='ä¿å­˜ä¸º.rrdæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-c', '--connect', action='store_true', 
                       help='è¿æ¥åˆ°è¿œç¨‹RerunæŸ¥çœ‹å™¨ (éœ€è¦å…ˆè¿è¡Œ `rerun`)')
    parser.add_argument('--explore', action='store_true', help='ä»…æ¢ç´¢æ–‡ä»¶ç»“æ„ï¼Œä¸è¿›è¡Œå¯è§†åŒ–')
    parser.add_argument('--addr', type=str, default='127.0.0.1:9876',
                       help='è¿œç¨‹RerunæŸ¥çœ‹å™¨åœ°å€ (é»˜è®¤: 127.0.0.1:9876)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥è·¯å¾„
    if not os.path.exists(args.input_path):
        debug_print("MAIN", f"è·¯å¾„ä¸å­˜åœ¨: {args.input_path}", "ERROR")
        sys.exit(1)
    
    # å¦‚æœåªæ˜¯æ¢ç´¢ç»“æ„
    if args.explore:
        if os.path.isfile(args.input_path):
            explore_hdf5_structure(args.input_path)
        else:
            hdf5_files = [f for f in os.listdir(args.input_path) 
                         if f.endswith('.hdf5') or f.endswith('.h5')]
            if not hdf5_files:
                debug_print("MAIN", f"åœ¨æ–‡ä»¶å¤¹ {args.input_path} ä¸­æœªæ‰¾åˆ°HDF5æ–‡ä»¶", "ERROR")
                sys.exit(1)
            for hdf5_file in hdf5_files:
                explore_hdf5_structure(os.path.join(args.input_path, hdf5_file))
        return
    
    # åˆå§‹åŒ–Rerun
    app_id = f"hdf5_visualization/{Path(args.input_path).stem}"
    
    if args.save:
        # ä¿å­˜æ¨¡å¼
        debug_print("MAIN", f"å°†æ•°æ®ä¿å­˜åˆ°: {args.save}", "INFO")
        rr.init(app_id, spawn=False)
        rr.save(args.save)
    elif args.connect:
        # è¿æ¥åˆ°è¿œç¨‹æŸ¥çœ‹å™¨
        debug_print("MAIN", f"è¿æ¥åˆ°RerunæŸ¥çœ‹å™¨: {args.addr}", "INFO")
        debug_print("MAIN", "è¯·ç¡®ä¿å·²è¿è¡Œ: rerun", "INFO")
        rr.init(app_id, spawn=False)
        rr.connect(args.addr)
    else:
        # é»˜è®¤ï¼šåœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
        debug_print("MAIN", "å¯åŠ¨RerunæŸ¥çœ‹å™¨...", "INFO")
        rr.init(app_id, spawn=True)
    
    # å¤„ç†è¾“å…¥
    if os.path.isfile(args.input_path):
        # å•ä¸ªæ–‡ä»¶
        debug_print("MAIN", f"å¯è§†åŒ–æ–‡ä»¶: {args.input_path}", "INFO")
        try:
            visualize_hdf5_with_rerun(args.input_path, verbose=args.verbose)
            debug_print("MAIN", "å¯è§†åŒ–å®Œæˆ!", "INFO")
            debug_print("MAIN", "æç¤º: åœ¨RerunæŸ¥çœ‹å™¨ä¸­å¯ä»¥:", "INFO")
            debug_print("MAIN", "  - ä½¿ç”¨æ—¶é—´è½´æ»‘å—å›æ”¾æ•°æ®", "INFO")
            debug_print("MAIN", "  - ç‚¹å‡»å·¦ä¾§é¢æ¿å±•å¼€/æŠ˜å æ•°æ®é¡¹", "INFO")
            debug_print("MAIN", "  - ä½¿ç”¨é¼ æ ‡ç¼©æ”¾å’Œå¹³ç§»å›¾åƒ", "INFO")
            debug_print("MAIN", "  - åŒæ—¶æŸ¥çœ‹å¤šä¸ªæ•°æ®æµ", "INFO")
        except Exception as e:
            debug_print("MAIN", f"å¤„ç†å¤±è´¥: {e}", "ERROR")
            if args.verbose:
                import traceback
                traceback.print_exc()
            sys.exit(1)
    else:
        # æ–‡ä»¶å¤¹
        debug_print("MAIN", f"å¯è§†åŒ–æ–‡ä»¶å¤¹: {args.input_path}", "INFO")
        visualize_folder_with_rerun(args.input_path, verbose=args.verbose)
        debug_print("MAIN", "æ‰¹é‡å¯è§†åŒ–å®Œæˆ!", "INFO")
    
    # å¦‚æœæ˜¯ä¿å­˜æ¨¡å¼ï¼Œä¸éœ€è¦ç­‰å¾…
    if not args.save:
        debug_print("MAIN", "æŒ‰ Ctrl+C é€€å‡º", "INFO")
        try:
            # ä¿æŒç¨‹åºè¿è¡Œï¼Œä»¥ä¾¿æŸ¥çœ‹å™¨ä¿æŒæ‰“å¼€
            import time
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            debug_print("MAIN", "é€€å‡ºç¨‹åº", "INFO")


if __name__ == "__main__":
    main()

